# global configs
Global:
  checkpoints: null
  pretrained_model: null
  output_dir: ./output/
  device: gpu
  save_interval: 100
  eval_during_train: True
  eval_interval: 1
  epochs: 40
  print_batch_step: 10
  use_visualdl: True
  # used for static mode and model export
  image_shape: [3, 112, 112]
  save_inference_dir: ./inference
  seed: 25235


# model architecture
Arch:
  name: APViT
  class_num: 7
 
# loss function config for traing/eval process
Loss:
  Train:
    - CELoss:
        weight: 1.0
  Eval:
    - CELoss:
        weight: 1.0


Optimizer:
  name: Momentum
  momentum: 0.9
  lr:
    name: Cosine
    learning_rate: 0.001
  regularizer:
    name: 'L2'
    coeff: 0
  clip_norm: 10


# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: RAFDataset
      image_root: data/RAF-DB/basic/Image/aligned_224/
      cls_label_path: data/RAF-DB/basic/EmoLabel/train.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - ResizeImage:
            resize_short: 150
        - RandCropImage:
            size: 112
        - RandFlipImage:
            flip_code: 1
        - AutoAugment:
        # - RandAugment:
        #     num_layers: 2
        #     magnitude: 2
        - NormalizeImage:
            scale: 1.0
            mean: [123.675, 116.28, 103.53]
            std: [58.395, 57.12, 57.375]
            order: ''
        - RandomErasing:
            EPSILON: 0.5
            sl: 0.02
            sh: 0.4
            r1: 0.3
            mean: [0., 0., 0.]

    sampler:
      # name: DistributedBatchSampler
      name: DistributedOverSampler
      batch_size: 128
      drop_last: False
      shuffle: True
    loader:
      num_workers: 4
      use_shared_memory: True

  Eval:
    dataset: 
      name: RAFDataset
      image_root: data/RAF-DB/basic/Image/aligned_224/
      cls_label_path: data/RAF-DB/basic/EmoLabel/test.txt
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - ResizeImage:
            resize_short: 112
        # - CropImage:
        #     size: 112
        - NormalizeImage:
            scale: 1.0
            mean: [123.675, 116.28, 103.53]
            std: [58.395, 57.12, 57.375]
            order: ''
    sampler:
      name: DistributedBatchSampler
      batch_size: 128
      drop_last: False
      shuffle: False
    loader:
      num_workers: 4
      use_shared_memory: True

Infer:
  infer_imgs: docs/images/whl/demo.jpg
  batch_size: 10
  transforms:
    - DecodeImage:
        to_rgb: True
        channel_first: False
    - ResizeImage:
        resize_short: 256
    - CropImage:
        size: 224
    - NormalizeImage:
        scale: 1.0/255.0
        mean: [0.5, 0.5, 0.5]
        std: [0.5, 0.5, 0.5]
        order: ''
    - ToCHWImage:
  PostProcess:
    name: Topk
    topk: 5
    class_id_map_file: ppcls/utils/imagenet1k_label_list.txt

Metric:
  Train:
    - TopkAcc:
        topk: [1, 3]
  Eval:
    - TopkAcc:
        topk: [1, 3]
